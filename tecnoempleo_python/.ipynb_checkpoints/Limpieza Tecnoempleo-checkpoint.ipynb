{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c5ae83-5e6b-4fdd-91a9-aa079316d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta personalizada (cambia esto por tu ruta)\n",
    "#ruta_guardado = \"C:/Users/TuUsuario/Documents/MiCarpeta/salarios.csv\"  # Windows\n",
    "# ruta_guardado = \"/home/tuusuario/Documents/MiCarpeta/salarios.csv\"  # Linux/macOS\n",
    "\n",
    "# Guardar el DataFrame en la ruta especificada\n",
    "#df.to_csv(ruta_guardado, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "#print(f\"Archivo guardado en: {ruta_guardado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8376a0f-feda-4959-b4f5-1394266e71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "from rapidfuzz import process, fuzz\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08329735-b6d7-4b13-9e99-01e0f68f0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Proyecto final/ofertas_tecnoempleo.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfd6b6-96a9-4c9f-b4b4-b3e1f1488494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Código para ver el df completo \n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145eeed-7484-4dee-b31e-6304be6029ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un id para cada oferta y ponemos la columna en primera posición:\n",
    "\n",
    "df[\"id\"] = [\"id_tec_\" + str(i) for i in range(1, len(df) + 1)]\n",
    "columna_extraida_ = df.pop(\"id\")\n",
    "df.insert(0, \"id\", columna_extraida_) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db4219-741b-49fc-bb93-fc465bb17682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos df matricial de tecnologías, lo pasamos a csv y eliminamos las columnas\n",
    "df_tecnologias_matricial = df[[df.columns[0]] + list(df.columns[25:])]\n",
    "lista_tecnologias = list(df.columns[25:])\n",
    "\n",
    "df_tecnologias_matricial.to_csv(\"tecnologias_matricial_tecnoempleo.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "df.drop(columns=lista_tecnologias, inplace=True)\n",
    "df_tecnologias_matricial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddc0a8-430d-4f4c-a714-ed9cc3a59a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos la columna con título vacío (columna con información de trabajo remoto o no):\n",
    "df.rename(columns={\"Unnamed: 7\": \"Teletrabajo\"}, inplace=True)\n",
    "df[\"Teletrabajo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67d518b-d888-4b28-b7a4-cd8ab5422d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De la información que nos quedamos en la columna de Teletrabajo, unificamos los valores por: 100% en remoto, híbrido y presencial.\n",
    "df[\"Teletrabajo\"] = df[\"Teletrabajo\"].apply(lambda x: \"Remoto\" if \"Remoto\" in x or \"Teletrabajo\" in x else \"Híbrido\" if \"Híbrido\" in x else \"Presencial\")\n",
    "\n",
    "# Verificamos los resultados\n",
    "df[\"Teletrabajo\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2221afa-ccd2-4067-b880-ad068c949ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos la columna de Fecha de publicación, eliminando el texto que nos sobra y convirtiendo a datetime:\n",
    "df[\"Fecha publicacion\"] = df[\"Fecha publicacion\"].str.replace(\"Actualizada\", \"\").str.replace(\"Nueva\", \"\")\n",
    "df[\"Fecha publicacion\"] = pd.to_datetime(df[\"Fecha publicacion\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55b40d2-4f60-4cc4-90a7-87d1cee31aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitamos los caracteres no deseados de la columna Idiomas y dividimos la columna en dos: una para el idioma y otra para el nivel.\n",
    "df[\"Idiomas\"] = df[\"Idiomas\"].fillna(\"\")\n",
    "df[\"Idiomas\"] = df[\"Idiomas\"].str.replace(r\"[\\t\\r\\n|]\", \"\", regex=True)\n",
    "\n",
    "# Extraemos todos los Idiomas y niveles\n",
    "def extraer_Idiomas_niveles(texto):\n",
    "    if not texto.strip():  \n",
    "        return np.nan, np.nan\n",
    "    matches = re.findall(r\"(\\w+)\\s*\\((\\w+)\\)\", texto)\n",
    "    if not matches:s\n",
    "        return np.nan, np.nan \n",
    "    Idiomas = [match[0] for match in matches]\n",
    "    niveles = [match[1] for match in matches]\n",
    "\n",
    "    # Unimos los Idiomas y niveles en cadenas separadas por comas\n",
    "    return \", \".join(Idiomas), \", \".join(niveles)\n",
    "\n",
    "\n",
    "df[[\"Idiomas_limpios\", \"niveles_limpios\"]] = df[\"Idiomas\"].apply(extraer_Idiomas_niveles).apply(pd.Series)\n",
    "\n",
    "\n",
    "df[\"Idiomas_limpios\"] = df[\"Idiomas_limpios\"].replace(\"\", np.nan)\n",
    "df[\"niveles_limpios\"] = df[\"niveles_limpios\"].replace(\"\", np.nan)\n",
    "\n",
    "\n",
    "df.drop(columns=[\"Idiomas\"], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd60728-3850-4434-9f3c-c80d99605e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe solo con id, idiomas y niveles limpios\n",
    "df_idiomas1 = df[[\"id\",\"Idiomas_limpios\",\"niveles_limpios\"]]\n",
    "\n",
    "# Por cada idioma y nivel, creamos un diccionario con el id, idioma y nivel y los añade a una lista\n",
    "dict_list = []\n",
    "for i, row in df_idiomas1.iterrows():\n",
    "    if pd.notna(row[\"Idiomas_limpios\"]) and pd.notna(row[\"niveles_limpios\"]):\n",
    "        idiomas = row[\"Idiomas_limpios\"].split(\", \")\n",
    "        niveles = row[\"niveles_limpios\"].split(\", \")\n",
    "        for idioma, nivel in zip(idiomas, niveles):\n",
    "            dict_list.append({\"id\": row[\"id\"], \"idioma\": idioma, \"nivel\": nivel})\n",
    "    else:\n",
    "        dict_list.append({\"id\": row[\"id\"], \"idioma\": None, \"nivel\": None})\n",
    "\n",
    "df.drop(columns = [\"Idiomas_limpios\", \"niveles_limpios\"], inplace = True)\n",
    "# Convertimos la lista de diccionarios a un dataframe\n",
    "df_idiomas = pd.DataFrame(dict_list)\n",
    "\n",
    "df_idiomas \n",
    "\n",
    "df_idiomas.to_csv('idiomas_tecnoempleo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74efb7da-3e86-43b1-a454-e3ce217aa7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos la columna de Salario y la unificamos a bruto por año.\n",
    "\n",
    "# Separamos las columnas para crear una con la unidad reflejada (mes, año, hora):\n",
    "split_data = df[\"Salario\"].str.split(\" Bruto/\", expand=True)\n",
    "df[\"Rango\"] = split_data[0]  \n",
    "df[\"Unidad\"] = split_data[1] \n",
    "\n",
    "# Dividimos los valores para hacer dos columnas de mínimo y máximo:\n",
    "rango_split = df[\"Rango\"].str.split(\"-\\xa0\", expand=True)\n",
    "df[\"Min\"] = rango_split[0].str.replace(\"€\", \"\").str.replace(\".\", \"\").str.strip().astype(float)\n",
    "df[\"Max\"] = rango_split[1].str.replace(\"€\", \"\").str.replace(\".\", \"\").str.strip().astype(float)\n",
    "\n",
    "# Usamos where para cambiar la palabra mes por 12 y hora por 2080 (40h a la semana por 52 semanas):\n",
    "df[\"Factor\"] = np.where(\n",
    "    df[\"Unidad\"] == \"mes\", 12,\n",
    "    np.where(df[\"Unidad\"] == \"hora\", 2080, 1)\n",
    ")\n",
    "# Multiplicamos las columnas y dividimos por mil para una mejor visualización:\n",
    "df[\"salario_desde\"] = df[\"Min\"] * df[\"Factor\"] / 1000\n",
    "df[\"salario_hasta\"] = df[\"Max\"] * df[\"Factor\"] / 1000\n",
    "\n",
    "df.drop(columns=[\"Rango\", \"Unidad\", \"Min\", \"Max\", \"Factor\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37592f0-6daf-4f8a-bff7-7122a081ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la información de la columna de habilidades, creamos un nuevo DF:\n",
    "df_habilidades_te = df[[\"id\", \"Habilidades\"]].copy()\n",
    "\n",
    "# Transformamos de string a lista: \n",
    "df_habilidades_te[\"Habilidades\"] = df_habilidades_te[\"Habilidades\"].apply(ast.literal_eval)\n",
    "\n",
    "# Creamos una lista con las habilidades sin duplicar:\n",
    "todas_habilidades = sum(df_habilidades_te[\"Habilidades\"], [])\n",
    "habilidades_unicas = list(set(todas_habilidades))\n",
    "\n",
    "# Creamos columnas binarias para cada habilidad:\n",
    "for habilidad in habilidades_unicas:\n",
    "    df_habilidades_te[habilidad] = df_habilidades_te[\"Habilidades\"].apply(lambda x: 1 if habilidad in x else 0)\n",
    "\n",
    "df_habilidades_te.drop(columns=[\"Habilidades\"], inplace=True)\n",
    "\n",
    "# Creamos csv matricial de habilidades:\n",
    "df_habilidades_te.to_csv(\"habilidades_matricial_tecnoempleo.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf327c-c4fd-476d-a24e-c938c9561448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprescindible residir, cambiamos los valores para unicficarlos:\n",
    "df[\"Imprescindible Residir\"] = df[\"Imprescindible Residir\"].replace(\n",
    "    {\"España\": \"País Puesto\", \"Spain\": \"País Puesto\", \"Country\": \"País Puesto\", \n",
    "     \"Not Required\": \"No requerido\"})\n",
    "df[\"Imprescindible Residir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e2749-f365-4b67-8a13-ad55cb294f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a duplicar las filas por ID, para asociar todas las provincias relacionadas con ese ID y hacemos un nuevo DF:\n",
    "df_provincias = df[[\"id\", \"Otras Provincias\"]]\n",
    "\n",
    "df_provincias[\"Otras Provincias\"] = df_provincias[\"Otras Provincias\"].apply(lambda x: str(x).split(\", \") if pd.notna(x) else [None])\n",
    "\n",
    "df_provincias = df_provincias.explode(\"Otras Provincias\").reset_index(drop=True)\n",
    "\n",
    "df_provincias.to_csv(\"df_provincias.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df.drop(columns=[\"Otras Provincias\"], inplace=True)\n",
    "\n",
    "# Mostrar resultado\n",
    "print(df_provincias)\n",
    "# Falta hacer split por la y también"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e97e89-538f-4fee-92f9-0415910c52dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"limpieza_tecnoempleo.csv\", index=False, encoding=\"utf-8\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
